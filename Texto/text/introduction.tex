\chapter{Introdução}
\label{chp:introduction}

A cada ano novas aplicações e dispositivos com formatos e recursos diversos são lançados no mercado, o crescimento de aplicações como as de transporte, dos serviços de streamings, a popularização de  dispostivos IoT, o crescimento dos datacenters e do serviço em nuvem vêm contribuindo fortemente para o aumento na produção de dados \citep{relatorio-idc}.

Especializada em computação em nuvem, a \citeauthor{domo-study} realiza anualmente uma análise da quantidade de informação produzida na internet  a cada \textit{minuto}. Abaixo vemos algumas das estatísticas relativas à esse estudo \citep{domo-study}:

\begin{itemize}
    \item 41.666.667 mensagens são enviadas através do aplicativo de mensagens WhatsApp;
    \item 479.452 pessoas interagem com conteúdos da plataforma Reddit;
    \item 208.333 pessoas participam de conferências no serviço de chamada Zoom, ao passo que o Microsoft Teams conecta cerca de 52.083 usuários por minuto;
    \item 147.000 uploads de fotos são feitos no Facebook e 150.000 mensagens são enviadas na mesma plataforma;
    \item 28 faixas de música são incluídas no serviço de streaming Spotify;
    \item 500 horas de vídeos são enviadas ao youtube.
\end{itemize}

Prevê-se que, essa quantidade de dados irá crescer nos próximos anos. De acordo com o relatório anual da \citet{relatorio-cisco}, em 2018 o número de usuários conectados à internet era de 3,9 bilhões, até 2023 mais de 70\% da população terá acesso à internet, atingido a marca de 5,3 bilhões de usuários conectados. A International Data Corporation (IDC) prevê que em 2025, 75\% (6 bilhões) da população mundial interaja com aplicações diversas todos os dias, fazendo com que a quantidade de dados produzidos cresça de 33 Zetabytes (ZBs) em 2018, para 175 ZBs em 2025 \citep{relatorio-idc}.

Esse crescimento na produção de dados tem relação direta com o surgimento de novos dispositivos. O grande problema é que existe uma lacuna de
desempenho entre CPU e memória. Essa lacuna se deve principalmente ao fato de que os fabricantes de processadores estão focados em obter uma lógica rápida,  que acelera a comunicação, ao passo que os fabricantes de memória objetivam uma capacidade de armazenamento de dados maior \citep{paper-processor-memory-bottleneck}. Essa disparidade é um grande desafio para projetitas e desenvolvedores, pois como afirmam \citet{paper-processor-memory-bottleneck},  esta faz com que seja criado um atraso na comunicação entre CPU e memória (conhecido gargalo de Von-Neumann), sobretudo quando se trabalha com um grande conjunto de dados. Diversas soluções foram e estão sendo desenvolvidas para contornar o problema dessa lacuna, entre elas o uso de computação paralela em nível de instrução, hierarquia de memória multinível, \textit{smarter memories}, técnicas específicas de tolerância à latência, e compressão de dados \citep{paper-Processor-Memory-bottleneck-Problems-Solutions, paper-processor-memory-bottleneck}.

Como mostra \cite{book-compact-data-structures}, estruturas de dados sucintas são uma forma de compressão de dados. Elas representam a informação de maneira eficiente, usando um espaço próximo ao limite inferior estabelecido pela Teoria da Informação, possibilitando ainda operações sobre seus objetos de modo que não seja necessário que estes sejam descompactados, o que a torna mais eficiente do que os algoritimos de compactação  clássicos que precisam de armazenamento e tempo extra para descompactar os objetos sobre os quais operam.  Esses fatores fazem com que as estruturas de dados sucintas sejam amplamente usadas em sistemas como os de mecanismo de busca,  ou sistemas que trabalham com dados geográficos. Estruturas de dados sucintas também são essenciais para lidar  com dispositivos em que a quantidade de memória é limitada, como  dispositivos IoTs e embarcados \citep{book-compact-data-structures}. %Por fim, mesmo que seja necessário reter parte do conjunto de dados em um nível mais baixo da hierarquia de memória, onde o tempo para obter uma informação é maior, o uso de estruturas de dados sucintas ainda possibilitará aplicações eficientes, haja vista que o seu uso minimizará o número de acessos a  memórias mais lentas.

Com os dados residindo em memória principal, temos um novo gargalo, dessa vez entre memória cache e memória principal. Nesse sentido e tendo em vista a lacuna de desempenho crescente entre processador e memória RAM, faz-se necessário buscarmos formas de melhor utilizarmos a cache.  \citet{paper-making-btree-cache} implementaram em um de seus trabalhos, diferentes versões de uma estrutura denominada \textit{Cache-Sensitive Search Trees (CSS-Tree)}, a \textit{Cache-Sensitive B$^+$-Tree (CSB$^+$-Tree)}, que tem como objetivo melhorar o desempenho de operações de atualização existentes na \text{CSS-tree}, através da maximização da quantidade de dados em cada nó. Durante os experimentos foi constatado que a estrutura original apresentava melhor desempenho nas operações de pesquisa devido ao seu alto fator de ramificação, se comparado ao da \textit{CSB$^+$-tree}. Foi observado também que entre as diferentes versões da \text{CSB$^+$-tree} implementadas, os autores obtiveram melhor desempenho, tanto em operações de atualização, como de pesquisa, nas versões que tinham fator de ramificação mais alto.

Nesse trabalho, nos concentraremos no estudo de árvores, uma das estruturas mais populares no campo da Ciência da Computação. De acordo com \citet{paper-succint-trees-in-practice}, no caso das árvores sucintas, as diferentes versões existentes na literatura podem diferir em sua funcionalidade, variando daquelas que suportam navegação de um nó filho para um nó pai ou aquelas que suportam operações como obter o ancestral comum mais baixo de dois nós, até aquelas que suportam um conjunto completo de operações, podendo variar em relação ao espaço ocupado, indo  de $O(n/(\log \log n)^2)$ à $O(n/ polylog(n))$ bits.

A nossa contribuição consiste na proposta de uma versão alternativa, de uma estrutura de dados sucinta já existente: a range min-Max tree (rmM-tree), de \cite{paper-fully-functinal-succint-trees}. Essa estrutura fornece suporte à diversas operações sobre árvores compactas. Em sua versão estática, ela pode ser construída usando apenas $n + O(\frac{n}{b} \log n)$ bits de espaço, sendo capaz de realizar operações em tempo $O(\log n)$\citep{paper-fully-functinal-succint-trees}. Essa estrutura é construída no formato de uma árvore binária completa, e portanto, possuí um baixo fator de ramificação. Assim, com base no exposto por \citet{paper-making-btree-cache}, propomos então uma versão da rmM-tre binária, no formato de árvore k-ária, afim de maximizar o fator de ramificação da range min-Max tree. Nossa estrutura se baseia também em um número maior de entradas por nó, visando aumentar o volume de dados enviados a cache em cada transferência, aproveitando do a localidade espacial\footnote{"itens cujos endereços estão próximos um do outro costumam ser referenciados em curto espaço de tempo" \citep{book-computer-architecutre}}, o que pode melhorar significativamente o desempenho de sistemas de buscas que lidam com grandes quantidade de dados.



% \section{Metodologia}
% Esse estudo será feito com base na revisão bibliográfica da estrutura proposta por \citet{paper-fully-functinal-succint-trees}, visando melhor entendimento das operações de navegação e consulta sobre árvores. Implementaremos a versão original da rmM-tree, buscando abranger todas as operações suportadas na literatura, além da versão original será implementada a versão alternativa da rmM-tree, no formato de árvore k-ária, com até k entradas por nó. Para realizar a validação das nossas implementações, usaremos a biblioteca \textit{Succint Data Structure Library (SDSL)}, uma biblioteca construída em C++, com código aberto e de alta qualidade, que reúne os destaques de $40$ publicações de pesquisa \citep{sdsl-article}. Auxiliará na validação das respostas das estruturas implementadas o framework Google Tests. Já o desempenho das estruturas será analisado mediante o uso do framework Google Benchmark.



\section{Estrutura do documento}
De modo a atingir os objetivos citados, o Capítulo~\ref{ch:fundamentacao} traz um estudo sobre hierarquia de memória, estrutura de dados sucintas e as características e operações suportadas pela range min-Max tree, ao final deste capítulo trazemos uma discussão acerca do aproveitamento efetivo da cache. O Capítulo~\ref{chp:desenvolvimento} apresenta a nossa versão da rmM-tree k-ária, expondo suas principais características e diferenças em relação à estrutura clássica. O Capítulo~\ref{chp:resultados}, discorre a respeito dos testes experimentais, metodologia usada para os mesmos e resultados alcançados. Por fim o Capítulo~\ref{chp:conclusao} expõe as nossas conclusões em relação 
aos objetivos e resultados alcançados, bem como as nossas perspectivas em relação aos trabalhos futuros.
%contextualizar a representação sucinta de dados, falar de maneira menos técnica questões de memória. Estruturas sucintas de modo geral, uma delas são as árvores sucintas, trazer exemplos de aplicações. Para que servem as árvores, que tipo de aplicação são usadas.
%deixsr claro a proposta
%manter objetivos

%\figref{fig:research-methodology-thesis} shows
%the multimethod research design applied in this thesis.
%\begin{figure}[h]
%\centering
%  \caption[Research methodology.]{The research methodology applied for this
%  thesis.}
%  \includegraphics[width=\columnwidth]{images/research-methodology-thesis.pdf}
%  \footnotesize{Source: Made by the author.}
%  \label{fig:research-methodology-thesis}
%\end{figure}

